{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Fashion MNIST Coding Project\n",
    "Build your own CNN on Fashion MNIST following the hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Imports & Dataset ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0dcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load and preprocess dataset ---\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_train = X_train[..., None]\n",
    "X_test = X_test[..., None]\n",
    "\n",
    "print('Training samples:', X_train.shape[0])\n",
    "print('Test samples:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Build a Simple CNN ---\n",
    "# TODO: Build your CNN using Conv2D, MaxPooling2D, Flatten, Dense\n",
    "# Hint: start with 2 Conv layers + 2 MaxPooling layers + Flatten + Dense\n",
    "model = None  # replace with your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Compile the Model ---\n",
    "# TODO: Compile your model\n",
    "# Hint: optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Train the Model ---\n",
    "# TODO: Train the model for 5 epochs\n",
    "# Use validation_data=(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Evaluate the Model ---\n",
    "# TODO: Evaluate your model on test data\n",
    "# TODO: Make a prediction for a random test image and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d278cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Plot Training History ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Make a Prediction ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Exploration ---\n",
    "# Experiment: change layer sizes, activations, add dropout, adjust epochs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. (Optional) Test Your Model on a New Image ---\n",
    "\n",
    "#  Try your trained model on a new image (not from the dataset)\n",
    "\n",
    "# Step 1: Download or load an image (any fashion item or similar)\n",
    "# Hint: You can use PIL or OpenCV to load the image\n",
    "# Example:\n",
    "# from PIL import Image\n",
    "# img = Image.open(\"path_to_your_image.jpg\").convert('L')  # convert to grayscale\n",
    "\n",
    "# Step 2: Preprocess the image\n",
    "# - Resize it to 28x28 (same as Fashion MNIST)\n",
    "# - Normalize pixel values to [0,1]\n",
    "# - Reshape to (1,28,28,1) for prediction\n",
    "\n",
    "# Step 3: Make a prediction\n",
    "# pred = model.predict(img_array)\n",
    "# print(\"Predicted class:\", np.argmax(pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda41328",
   "metadata": {},
   "source": [
    "Hint : Make sure the image is similar to Fashion MNIST items for correct prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a126f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. (Optional) TASK: webcam image Capture & Preprocessing ---\n",
    "#  Create an image dataset with your webcam\n",
    "\n",
    "# You can use this repository: https://github.com/bonartm/imageclassifier\n",
    "#\n",
    "# Your task:\n",
    "# 1. Clone or download the repository above\n",
    "# 2. Use the webcam capture tool to take a single image\n",
    "# 3. Apply the same preprocessing steps that are used for image classification\n",
    "# 4. Save both the original captured image and the preprocessed version\n",
    "#\n",
    "# Preprocessing steps to implement:\n",
    "# - Extract the 224x224 region from the captured frame\n",
    "# - Convert from BGR to RGB color format\n",
    "# - Normalize pixel values to [0, 1] range\n",
    "# - Display the shape and dtype of the image after each step\n",
    "#\n",
    "# Hint: Look at the capture.py and utils.py files in the repo to understand\n",
    "# how images are captured and saved. You'll need to add preprocessing functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf739e57",
   "metadata": {},
   "source": [
    "### --- 11. (Optional) TASK: webcam image Capture & Preprocessing ---\n",
    "\n",
    "In this task, you will create a small image dataset using your webcam and preprocess it for image classification. This is optional but a good hands-on extension of the project.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. **Clone or download** the repository: [bonartm/imageclassifier](https://github.com/bonartm/imageclassifier)\n",
    "2. Use the **webcam capture tool** in the repository to take a single image.\n",
    "3. Apply the following **preprocessing steps** on the captured image:\n",
    "   - Extract a 224x224 region from the frame (center crop or resize)\n",
    "   - Convert from **BGR** (OpenCV default) to **RGB**\n",
    "   - Normalize pixel values to the **[0,1] range**\n",
    "   - Display the **shape** and **dtype** of the image after each step\n",
    "4. **Save both**:\n",
    "   - The original captured image\n",
    "   - The preprocessed image\n",
    "\n",
    "### Hints\n",
    "- Look at `capture.py` and `utils.py` in the repo to understand how images are captured and saved.\n",
    "- You can write **separate preprocessing functions** for each step to make your code modular.\n",
    "- Use meaningful file names when saving images, e.g., `captured_original.png` and `captured_preprocessed.png`.\n",
    "\n",
    "### Deliverable\n",
    "- Python script or notebook demonstrating:\n",
    "  - Image capture\n",
    "  - Step-by-step preprocessing\n",
    "  - Display of image shapes and dtypes\n",
    "  - Saved original and preprocessed images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228576e",
   "metadata": {},
   "source": [
    "For real webcam input, make sure the background is simple, and the object fits in the frame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
